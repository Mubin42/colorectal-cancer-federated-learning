{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZo78KuDY_IX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abe9a20-094e-4f79-9d61-76a998667be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
            "Compute dtype: float16\n",
            "Variable dtype: float32\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import gc\n",
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_policy(policy)\n",
        "print('Compute dtype: %s' % policy.compute_dtype)\n",
        "print('Variable dtype: %s' % policy.variable_dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r7gHOfTZQyy",
        "outputId": "cd5d0a31-029c-480a-865d-5b851f97af51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dF1sA5ggaK8B"
      },
      "outputs": [],
      "source": [
        "train_directory = \"/content/drive/MyDrive/Thesis Dataset/train\"\n",
        "test_directory = \"/content/drive/MyDrive/Thesis Dataset/test\"\n",
        "validation_directory = \"/content/drive/MyDrive/Thesis Dataset/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "USWl2VXCaRrr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ_sULALaYJK",
        "outputId": "e8b6c002-eec7-4b13-8683-391f68891ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6970/6970 [03:19<00:00, 35.00it/s] \n",
            "100%|██████████| 7028/7028 [02:33<00:00, 45.64it/s] \n",
            "100%|██████████| 8052/8052 [04:07<00:00, 32.49it/s] \n",
            "100%|██████████| 8052/8052 [03:18<00:00, 40.49it/s] \n",
            "100%|██████████| 6248/6248 [02:37<00:00, 39.69it/s] \n",
            "100%|██████████| 9548/9548 [03:33<00:00, 44.64it/s] \n",
            "100%|██████████| 6137/6137 [02:36<00:00, 39.14it/s] \n",
            "100%|██████████| 7040/7040 [02:33<00:00, 45.78it/s] \n",
            "100%|██████████| 10010/10010 [04:07<00:00, 40.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "DATADIR = train_directory\n",
        "\n",
        "CATEGORIES = [\"ADI\", \"BACK\",\"DEB\", \"LYM\",\"MUC\", \"MUS\",\"NORM\", \"STR\",\"TUM\"]\n",
        "\n",
        "training_data = []\n",
        "\n",
        "IMG_SIZE = 50\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES: \n",
        "\n",
        "        path = os.path.join(DATADIR,category)  \n",
        "        class_num = CATEGORIES.index(category) \n",
        "\n",
        "        for img in tqdm(os.listdir(path)): \n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                \n",
        "                training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                print(e)\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkL90xEwbh1I",
        "outputId": "599c2c3e-f560-4882-ae22-fb0b88e314b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:26<00:00, 38.05it/s]\n",
            "100%|██████████| 1069/1069 [00:16<00:00, 66.49it/s] \n",
            "100%|██████████| 1207/1207 [00:24<00:00, 48.51it/s] \n",
            "100%|██████████| 1233/1233 [00:29<00:00, 42.00it/s] \n",
            "100%|██████████| 1026/1026 [00:16<00:00, 63.73it/s] \n",
            "100%|██████████| 1364/1364 [00:29<00:00, 45.84it/s] \n",
            "100%|██████████| 877/877 [00:11<00:00, 75.62it/s] \n",
            "100%|██████████| 1164/1164 [00:25<00:00, 45.44it/s] \n",
            "100%|██████████| 1452/1452 [00:23<00:00, 62.46it/s] \n"
          ]
        }
      ],
      "source": [
        "DATADIR = test_directory\n",
        "\n",
        "CATEGORIES = [\"ADI\", \"BACK\",\"DEB\", \"LYM\",\"MUC\", \"MUS\",\"NORM\", \"STR\",\"TUM\"]\n",
        "\n",
        "testing_data = []\n",
        "\n",
        "IMG_SIZE = 50\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES: \n",
        "\n",
        "        path = os.path.join(DATADIR,category)  \n",
        "        class_num = CATEGORIES.index(category) \n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  \n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                \n",
        "                testing_data.append([new_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                print(e)\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YLmLaRnBcKcB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wAd3AqRLcTiZ"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "    \n",
        "\n",
        "X_train = np.array(X)\n",
        "X_train = X_train/255.0\n",
        "y_train = np.array(y)\n",
        "\n",
        "\n",
        "X_t = []\n",
        "y_t = []\n",
        "\n",
        "for features,label in testing_data:\n",
        "    X_t.append(features)\n",
        "    y_t.append(label)\n",
        "\n",
        "X_test = np.array(X_t)\n",
        "X_test = X_test/255.0\n",
        "y_test = np.array(y_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3PsVblLgdJmT"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4j363FddMu1",
        "outputId": "1080b7b4-10d8-4770-85cf-2b270a85bc8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10392"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fFVPHBzedPlY"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RU5YqicrdRi6"
      },
      "outputs": [],
      "source": [
        "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as \n",
        "                data shards - tuple of images and label lists.\n",
        "        args: \n",
        "            image_list: a list of numpy arrays of training images\n",
        "            label_list:a list of binarized labels for each image\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1 \n",
        "            \n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "    \n",
        "    data = list(zip(image_list, label_list))\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jzwqVvBIdav5"
      },
      "outputs": [],
      "source": [
        "clients = create_clients(X_train, y_train, num_clients=10, initial='client')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9eA1Fhy4dg_-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def batch_data(data_shard, bs=32):\n",
        "    '''Takes in a clients data shard and create a tfds object off it\n",
        "    args:\n",
        "        shard: a data, label constituting a client's data shard\n",
        "        bs:batch size\n",
        "    return:\n",
        "        tfds object'''\n",
        "    #seperate shard into data and labels lists\n",
        "    data, label = zip(*data_shard)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "    return dataset.shuffle(len(label)).batch(bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lC7yJLqEduXQ"
      },
      "outputs": [],
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "co = 0\n",
        "for (client_name, data) in clients.items():\n",
        "    co+=1\n",
        "    clients_batched[client_name] = batch_data(data)\n",
        "    \n",
        "   \n",
        "    \n",
        "#process and batch the test set  \n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEwSszLsd8pz",
        "outputId": "fe74a724-7320-441d-8e72-ab908adca6b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_1': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_10': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_2': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_3': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_4': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_5': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_6': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_7': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_8': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>,\n",
              " 'client_9': <BatchDataset element_spec=(TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 9), dtype=tf.float32, name=None))>}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "clients_batched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnFPz5NHeaNo",
        "outputId": "1677b790-82bf-45a5-97ea-c303bf0845c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "del(X_train)\n",
        "del(y_train)\n",
        "del(training_data)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XUgV30CDrgMO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MpgLwsYsYjL",
        "outputId": "14c7f817-465d-4670-d2b7-51247b1981b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-vlpefv5m\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-vlpefv5m\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.5.2)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20046 sha256=e40e6a94dd7d6685dcada9d950b1b7299ee130a0bc7babf2302eda450cc5d80d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j6419b05/wheels/0b/96/56/27b17c903efc647c51e4f364bfc20aa67f8d3dccad63c4fb4e\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0Jk4nhN-elV8"
      },
      "outputs": [],
      "source": [
        "from classification_models.tfkeras import Classifiers\n",
        "\n",
        "\n",
        "\n",
        "class SimpleModel:\n",
        "    def build(self):\n",
        "\n",
        "        # image_size = [75, 75]\n",
        "        # model1 = VGG16(include_top= False, input_shape=image_size+[3], weights='imagenet')\n",
        "        # headModel = model1.output\n",
        "        # headModel = layers.Flatten()(headModel)\n",
        "        # headModel = Dense(1024, activation=\"relu\")(headModel)\n",
        "        # headModel = Dropout(0.5)(headModel)\n",
        "        # headModel = Dense(9, activation=\"softmax\")(headModel)\n",
        "        # new_model = Model(inputs=model1.input, outputs=headModel)\n",
        "\n",
        "        # model2 = VGG19(include_top= False, input_shape=image_size+[3], weights='imagenet')\n",
        "        # headModel = model2.output\n",
        "        # headModel = layers.Flatten()(headModel)\n",
        "        # headModel = Dense(1024, activation=\"relu\")(headModel)\n",
        "        # headModel = Dropout(0.5)(headModel)\n",
        "        # headModel = Dense(9, activation=\"softmax\")(headModel)\n",
        "        # new_model1 = Model(inputs=model2.input, outputs=headModel)\n",
        "\n",
        "\n",
        "\n",
        "        # model3 = InceptionV3(include_top= False, input_shape=image_size+[3], weights='imagenet')\n",
        "        # headModel = model3.output\n",
        "        # headModel = layers.Flatten()(headModel)\n",
        "        # headModel = Dense(1024, activation=\"relu\")(headModel)\n",
        "        # headModel = Dropout(0.5)(headModel)\n",
        "        # headModel = Dense(9, activation=\"softmax\")(headModel)\n",
        "        # new_model2 = Model(inputs=model3.input, outputs=headModel)\n",
        "\n",
        "        # model4 = ResNet50(include_top= False, input_shape=image_size+[3], weights='imagenet')\n",
        "        # headModel = model4.output\n",
        "        # headModel = layers.Flatten()(headModel)\n",
        "        # headModel = Dense(1024, activation=\"relu\")(headModel)\n",
        "        # headModel = Dropout(0.5)(headModel)\n",
        "        # headModel = Dense(9, activation=\"softmax\")(headModel)\n",
        "        # new_model3 = Model(inputs=model4.input, outputs=headModel)\n",
        "\n",
        "        image_size = [50, 50]\n",
        "        ResNeXt50, preprocess_input = Classifiers.get('resnext50')\n",
        "        model5 = ResNeXt50(include_top = False, input_shape=image_size+[3], weights='imagenet')\n",
        "        headModel = model5.output\n",
        "        headModel = layers.Flatten()(headModel)\n",
        "        headModel = Dense(1024, activation=\"relu\")(headModel)\n",
        "        headModel = Dropout(0.5)(headModel)\n",
        "        headModel = Dense(9, activation=\"softmax\")(headModel)\n",
        "        new_model4 = Model(inputs=model5.input, outputs=headModel)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        inputs = keras.Input(shape=(50,50,3))\n",
        "        \n",
        "        # outputs = layers.average([new_model(inputs),new_model1(inputs),\n",
        "        #                           new_model2(inputs),new_model3(inputs),\n",
        "        #                           new_model4(inputs)])\n",
        "\n",
        "        outputs = new_model4(inputs)\n",
        "        ensemble_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "        \n",
        "        \n",
        "        return ensemble_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXe-XifDexIR",
        "outputId": "2427d8b6-865a-49bc-ac60-af2157759998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "optimizer = Adam(lr=.00001)\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = ['categorical_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SXb_5nFT-uSH"
      },
      "outputs": [],
      "source": [
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the bs\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
        "    print(global_count)\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
        "    return local_count/global_count\n",
        "\n",
        "\n",
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final\n",
        "\n",
        "\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "        \n",
        "    return avg_grad\n",
        "\n",
        "\n",
        "def test_local_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    #logits = model.predict(X_test, batch_size=100)\n",
        "    logits = model.predict(X_test)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    print('comm_round: {} | local_acc: {:.3%} | local_loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BG93nOe9-dP4"
      },
      "outputs": [],
      "source": [
        "def test_global_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    #logits = model.predict(X_test, batch_size=100)\n",
        "    logits = model.predict(X_test)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEDQWKf9e2-c",
        "outputId": "ebc7e624-153d-4034-b07a-34f4e60b1ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext50_imagenet_1000_no_top.h5\n",
            "94429184/94428600 [==============================] - 27s 0us/step\n",
            "94437376/94428600 [==============================] - 27s 0us/step\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 9)                 31446994  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,446,994\n",
            "Trainable params: 31,378,764\n",
            "Non-trainable params: 68,230\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
            "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "smlp_global = SimpleModel()\n",
        "global_model = smlp_global.build()\n",
        "global_model.summary()\n",
        "# from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "local_model = smlp_global.build()\n",
        "local_model.compile(optimizer= 'adam', loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIEV1VB_e5iz",
        "outputId": "d039de54-8d2c-4886-baf1-6e62f84434c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216/216 [==============================] - 78s 145ms/step - loss: 1.7716 - categorical_accuracy: 0.6212\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 2.0634 - categorical_accuracy: 0.4919\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 3.4380 - categorical_accuracy: 0.2632\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 3.5052 - categorical_accuracy: 0.3172\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 3.5386 - categorical_accuracy: 0.3978\n",
            "comm_round: 0 | local_acc: 9.623% | local_loss: 2.275390625\n",
            "69120\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 3.8318 - categorical_accuracy: 0.3154\n",
            "comm_round: 0 | local_acc: 11.201% | local_loss: 2.259765625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 2.2906 - categorical_accuracy: 0.4223\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 2.6761 - categorical_accuracy: 0.4767\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.26171875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 4.5418 - categorical_accuracy: 0.1925\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 3.0080 - categorical_accuracy: 0.5129\n",
            "comm_round: 0 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "comm_round: 0 | global_acc: 13.972% | global_loss: 2.197265625\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 1.0627 - categorical_accuracy: 0.6387\n",
            "comm_round: 1 | local_acc: 13.125% | local_loss: 2.1953125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 1.0609 - categorical_accuracy: 0.6358\n",
            "comm_round: 1 | local_acc: 7.304% | local_loss: 2.197265625\n",
            "69120\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 1.0534 - categorical_accuracy: 0.6498\n",
            "comm_round: 1 | local_acc: 9.873% | local_loss: 2.19921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 1.1043 - categorical_accuracy: 0.6184\n",
            "comm_round: 1 | local_acc: 11.615% | local_loss: 2.1953125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 1.0348 - categorical_accuracy: 0.6689\n",
            "comm_round: 1 | local_acc: 11.211% | local_loss: 2.197265625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 1.0628 - categorical_accuracy: 0.6371\n",
            "comm_round: 1 | local_acc: 10.287% | local_loss: 2.19921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 1.0352 - categorical_accuracy: 0.6462\n",
            "comm_round: 1 | local_acc: 11.422% | local_loss: 2.1953125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 1.0535 - categorical_accuracy: 0.6450\n",
            "comm_round: 1 | local_acc: 11.615% | local_loss: 2.193359375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 1.1081 - categorical_accuracy: 0.6242\n",
            "comm_round: 1 | local_acc: 9.873% | local_loss: 2.197265625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 1.0965 - categorical_accuracy: 0.6065\n",
            "comm_round: 1 | local_acc: 13.972% | local_loss: 2.1953125\n",
            "69120\n",
            "comm_round: 1 | global_acc: 11.615% | global_loss: 2.1953125\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.7259 - categorical_accuracy: 0.7830\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.7591 - categorical_accuracy: 0.7638\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.236328125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.7340 - categorical_accuracy: 0.7856\n",
            "comm_round: 2 | local_acc: 10.566% | local_loss: 2.220703125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.7359 - categorical_accuracy: 0.7856\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.7642 - categorical_accuracy: 0.7801\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.7914 - categorical_accuracy: 0.7646\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.7889 - categorical_accuracy: 0.7792\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.8434 - categorical_accuracy: 0.7542\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.7853 - categorical_accuracy: 0.7687\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.8337 - categorical_accuracy: 0.7529\n",
            "comm_round: 2 | local_acc: 10.287% | local_loss: 2.267578125\n",
            "69120\n",
            "comm_round: 2 | global_acc: 10.287% | global_loss: 2.22265625\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6460 - categorical_accuracy: 0.8153\n",
            "comm_round: 3 | local_acc: 5.822% | local_loss: 2.302734375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6750 - categorical_accuracy: 0.8067\n",
            "comm_round: 3 | local_acc: 14.097% | local_loss: 2.220703125\n",
            "69120\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 0.6265 - categorical_accuracy: 0.8211\n",
            "comm_round: 3 | local_acc: 10.373% | local_loss: 2.267578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.6459 - categorical_accuracy: 0.8111\n",
            "comm_round: 3 | local_acc: 18.351% | local_loss: 2.18359375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.7074 - categorical_accuracy: 0.8036\n",
            "comm_round: 3 | local_acc: 5.033% | local_loss: 2.3125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.7003 - categorical_accuracy: 0.7960\n",
            "comm_round: 3 | local_acc: 8.949% | local_loss: 2.25390625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6490 - categorical_accuracy: 0.8144\n",
            "comm_round: 3 | local_acc: 13.655% | local_loss: 2.236328125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.8401 - categorical_accuracy: 0.7648\n",
            "comm_round: 3 | local_acc: 10.344% | local_loss: 2.265625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6730 - categorical_accuracy: 0.8025\n",
            "comm_round: 3 | local_acc: 8.430% | local_loss: 2.28125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.6995 - categorical_accuracy: 0.7979\n",
            "comm_round: 3 | local_acc: 11.451% | local_loss: 2.255859375\n",
            "69120\n",
            "comm_round: 3 | global_acc: 11.172% | global_loss: 2.23046875\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5325 - categorical_accuracy: 0.8510\n",
            "comm_round: 4 | local_acc: 33.545% | local_loss: 2.041015625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5861 - categorical_accuracy: 0.8311\n",
            "comm_round: 4 | local_acc: 53.686% | local_loss: 1.8427734375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5876 - categorical_accuracy: 0.8341\n",
            "comm_round: 4 | local_acc: 34.902% | local_loss: 2.013671875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6258 - categorical_accuracy: 0.8227\n",
            "comm_round: 4 | local_acc: 70.150% | local_loss: 1.744140625\n",
            "69120\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 0.6623 - categorical_accuracy: 0.8095\n",
            "comm_round: 4 | local_acc: 50.587% | local_loss: 1.849609375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.7111 - categorical_accuracy: 0.7956\n",
            "comm_round: 4 | local_acc: 41.147% | local_loss: 1.9404296875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6530 - categorical_accuracy: 0.8088\n",
            "comm_round: 4 | local_acc: 52.579% | local_loss: 1.837890625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.6097 - categorical_accuracy: 0.8240\n",
            "comm_round: 4 | local_acc: 40.887% | local_loss: 1.9609375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.8010 - categorical_accuracy: 0.7556\n",
            "comm_round: 4 | local_acc: 20.958% | local_loss: 2.15234375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.6357 - categorical_accuracy: 0.8224\n",
            "comm_round: 4 | local_acc: 57.448% | local_loss: 1.81640625\n",
            "69120\n",
            "comm_round: 4 | global_acc: 58.227% | global_loss: 1.8232421875\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4776 - categorical_accuracy: 0.8605\n",
            "comm_round: 5 | local_acc: 69.717% | local_loss: 1.6875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4967 - categorical_accuracy: 0.8577\n",
            "comm_round: 5 | local_acc: 64.367% | local_loss: 1.751953125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5830 - categorical_accuracy: 0.8409\n",
            "comm_round: 5 | local_acc: 38.539% | local_loss: 1.9931640625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.5135 - categorical_accuracy: 0.8586\n",
            "comm_round: 5 | local_acc: 46.305% | local_loss: 1.8955078125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5615 - categorical_accuracy: 0.8389\n",
            "comm_round: 5 | local_acc: 42.821% | local_loss: 1.9384765625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.5431 - categorical_accuracy: 0.8468\n",
            "comm_round: 5 | local_acc: 73.355% | local_loss: 1.671875\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.5278 - categorical_accuracy: 0.8492\n",
            "comm_round: 5 | local_acc: 68.072% | local_loss: 1.7236328125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5532 - categorical_accuracy: 0.8434\n",
            "comm_round: 5 | local_acc: 52.040% | local_loss: 1.859375\n",
            "69120\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 0.6959 - categorical_accuracy: 0.7947\n",
            "comm_round: 5 | local_acc: 26.395% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.5338 - categorical_accuracy: 0.8499\n",
            "comm_round: 5 | local_acc: 31.765% | local_loss: 2.044921875\n",
            "69120\n",
            "comm_round: 5 | global_acc: 88.202% | global_loss: 1.5361328125\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.4292 - categorical_accuracy: 0.8761\n",
            "comm_round: 6 | local_acc: 66.301% | local_loss: 1.7041015625\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.4774 - categorical_accuracy: 0.8618\n",
            "comm_round: 6 | local_acc: 61.788% | local_loss: 1.763671875\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.4225 - categorical_accuracy: 0.8804\n",
            "comm_round: 6 | local_acc: 75.693% | local_loss: 1.6220703125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4301 - categorical_accuracy: 0.8752\n",
            "comm_round: 6 | local_acc: 58.699% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 146ms/step - loss: 0.4548 - categorical_accuracy: 0.8693\n",
            "comm_round: 6 | local_acc: 60.037% | local_loss: 1.7724609375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4573 - categorical_accuracy: 0.8655\n",
            "comm_round: 6 | local_acc: 76.415% | local_loss: 1.6357421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4287 - categorical_accuracy: 0.8709\n",
            "comm_round: 6 | local_acc: 38.674% | local_loss: 1.9912109375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.5116 - categorical_accuracy: 0.8539\n",
            "comm_round: 6 | local_acc: 69.130% | local_loss: 1.685546875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4857 - categorical_accuracy: 0.8652\n",
            "comm_round: 6 | local_acc: 51.472% | local_loss: 1.8564453125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.5632 - categorical_accuracy: 0.8364\n",
            "comm_round: 6 | local_acc: 19.159% | local_loss: 2.171875\n",
            "69120\n",
            "comm_round: 6 | global_acc: 83.391% | global_loss: 1.5576171875\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 0.3685 - categorical_accuracy: 0.8949\n",
            "comm_round: 7 | local_acc: 80.235% | local_loss: 1.5908203125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.4196 - categorical_accuracy: 0.8823\n",
            "comm_round: 7 | local_acc: 58.661% | local_loss: 1.810546875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4148 - categorical_accuracy: 0.8867\n",
            "comm_round: 7 | local_acc: 64.886% | local_loss: 1.7392578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3861 - categorical_accuracy: 0.8858\n",
            "comm_round: 7 | local_acc: 76.059% | local_loss: 1.638671875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4136 - categorical_accuracy: 0.8829\n",
            "comm_round: 7 | local_acc: 51.751% | local_loss: 1.8681640625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4252 - categorical_accuracy: 0.8807\n",
            "comm_round: 7 | local_acc: 61.952% | local_loss: 1.7568359375\n",
            "69120\n",
            "216/216 [==============================] - 31s 143ms/step - loss: 0.4745 - categorical_accuracy: 0.8602\n",
            "comm_round: 7 | local_acc: 60.527% | local_loss: 1.7783203125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.4534 - categorical_accuracy: 0.8726\n",
            "comm_round: 7 | local_acc: 44.650% | local_loss: 1.93359375\n",
            "69120\n",
            "216/216 [==============================] - 32s 147ms/step - loss: 0.4955 - categorical_accuracy: 0.8675\n",
            "comm_round: 7 | local_acc: 49.817% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.3939 - categorical_accuracy: 0.8913\n",
            "comm_round: 7 | local_acc: 66.744% | local_loss: 1.7294921875\n",
            "69120\n",
            "comm_round: 7 | global_acc: 91.349% | global_loss: 1.48828125\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3264 - categorical_accuracy: 0.9050\n",
            "comm_round: 8 | local_acc: 80.341% | local_loss: 1.578125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3469 - categorical_accuracy: 0.8990\n",
            "comm_round: 8 | local_acc: 69.043% | local_loss: 1.68359375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3715 - categorical_accuracy: 0.8933\n",
            "comm_round: 8 | local_acc: 64.540% | local_loss: 1.7314453125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4922 - categorical_accuracy: 0.8613\n",
            "comm_round: 8 | local_acc: 20.554% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3345 - categorical_accuracy: 0.9026\n",
            "comm_round: 8 | local_acc: 80.302% | local_loss: 1.5830078125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.3575 - categorical_accuracy: 0.8930\n",
            "comm_round: 8 | local_acc: 65.396% | local_loss: 1.7275390625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3414 - categorical_accuracy: 0.9058\n",
            "comm_round: 8 | local_acc: 67.244% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4109 - categorical_accuracy: 0.8909\n",
            "comm_round: 8 | local_acc: 17.783% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.5467 - categorical_accuracy: 0.8354\n",
            "comm_round: 8 | local_acc: 56.139% | local_loss: 1.8232421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3431 - categorical_accuracy: 0.9029\n",
            "comm_round: 8 | local_acc: 74.538% | local_loss: 1.63671875\n",
            "69120\n",
            "comm_round: 8 | global_acc: 94.140% | global_loss: 1.45703125\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5888 - categorical_accuracy: 0.8273\n",
            "comm_round: 9 | local_acc: 42.475% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4890 - categorical_accuracy: 0.8564\n",
            "comm_round: 9 | local_acc: 32.198% | local_loss: 2.0625\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2707 - categorical_accuracy: 0.9250\n",
            "comm_round: 9 | local_acc: 89.906% | local_loss: 1.48828125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5100 - categorical_accuracy: 0.8605\n",
            "comm_round: 9 | local_acc: 12.009% | local_loss: 2.201171875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2568 - categorical_accuracy: 0.9263\n",
            "comm_round: 9 | local_acc: 89.704% | local_loss: 1.4921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2680 - categorical_accuracy: 0.9215\n",
            "comm_round: 9 | local_acc: 89.732% | local_loss: 1.5078125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2873 - categorical_accuracy: 0.9265\n",
            "comm_round: 9 | local_acc: 81.457% | local_loss: 1.572265625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3068 - categorical_accuracy: 0.9155\n",
            "comm_round: 9 | local_acc: 83.122% | local_loss: 1.5849609375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3226 - categorical_accuracy: 0.9101\n",
            "comm_round: 9 | local_acc: 37.856% | local_loss: 2.009765625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3210 - categorical_accuracy: 0.9150\n",
            "comm_round: 9 | local_acc: 84.238% | local_loss: 1.5478515625\n",
            "69120\n",
            "comm_round: 9 | global_acc: 87.336% | global_loss: 1.5517578125\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5985 - categorical_accuracy: 0.8189\n",
            "comm_round: 10 | local_acc: 19.419% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2711 - categorical_accuracy: 0.9215\n",
            "comm_round: 10 | local_acc: 77.858% | local_loss: 1.603515625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2626 - categorical_accuracy: 0.9288\n",
            "comm_round: 10 | local_acc: 90.541% | local_loss: 1.4853515625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3496 - categorical_accuracy: 0.9169\n",
            "comm_round: 10 | local_acc: 74.769% | local_loss: 1.6279296875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2805 - categorical_accuracy: 0.9192\n",
            "comm_round: 10 | local_acc: 86.605% | local_loss: 1.5205078125\n",
            "69120\n",
            "216/216 [==============================] - 32s 147ms/step - loss: 0.2555 - categorical_accuracy: 0.9288\n",
            "comm_round: 10 | local_acc: 86.836% | local_loss: 1.5185546875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2526 - categorical_accuracy: 0.9291\n",
            "comm_round: 10 | local_acc: 75.683% | local_loss: 1.6181640625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.4622 - categorical_accuracy: 0.8780\n",
            "comm_round: 10 | local_acc: 39.530% | local_loss: 1.9609375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3035 - categorical_accuracy: 0.9150\n",
            "comm_round: 10 | local_acc: 57.063% | local_loss: 1.802734375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3003 - categorical_accuracy: 0.9228\n",
            "comm_round: 10 | local_acc: 83.131% | local_loss: 1.5654296875\n",
            "69120\n",
            "comm_round: 10 | global_acc: 93.736% | global_loss: 1.46484375\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2561 - categorical_accuracy: 0.9275\n",
            "comm_round: 11 | local_acc: 68.957% | local_loss: 1.689453125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.6439 - categorical_accuracy: 0.7881\n",
            "comm_round: 11 | local_acc: 9.623% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2553 - categorical_accuracy: 0.9295\n",
            "comm_round: 11 | local_acc: 75.510% | local_loss: 1.6298828125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2293 - categorical_accuracy: 0.9324\n",
            "comm_round: 11 | local_acc: 93.004% | local_loss: 1.4619140625\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2219 - categorical_accuracy: 0.9337\n",
            "comm_round: 11 | local_acc: 82.467% | local_loss: 1.5576171875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2866 - categorical_accuracy: 0.9205\n",
            "comm_round: 11 | local_acc: 57.304% | local_loss: 1.7958984375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2303 - categorical_accuracy: 0.9328\n",
            "comm_round: 11 | local_acc: 85.951% | local_loss: 1.53515625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2569 - categorical_accuracy: 0.9254\n",
            "comm_round: 11 | local_acc: 90.185% | local_loss: 1.486328125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2475 - categorical_accuracy: 0.9305\n",
            "comm_round: 11 | local_acc: 90.483% | local_loss: 1.4833984375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3400 - categorical_accuracy: 0.9032\n",
            "comm_round: 11 | local_acc: 85.826% | local_loss: 1.5322265625\n",
            "69120\n",
            "comm_round: 11 | global_acc: 93.052% | global_loss: 1.4677734375\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2674 - categorical_accuracy: 0.9294\n",
            "comm_round: 12 | local_acc: 60.614% | local_loss: 1.7724609375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2258 - categorical_accuracy: 0.9351\n",
            "comm_round: 12 | local_acc: 76.886% | local_loss: 1.619140625\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2449 - categorical_accuracy: 0.9240\n",
            "comm_round: 12 | local_acc: 85.999% | local_loss: 1.53125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3092 - categorical_accuracy: 0.9101\n",
            "comm_round: 12 | local_acc: 40.252% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2358 - categorical_accuracy: 0.9285\n",
            "comm_round: 12 | local_acc: 86.701% | local_loss: 1.544921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2421 - categorical_accuracy: 0.9301\n",
            "comm_round: 12 | local_acc: 84.344% | local_loss: 1.5595703125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2655 - categorical_accuracy: 0.9230\n",
            "comm_round: 12 | local_acc: 59.151% | local_loss: 1.77734375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2381 - categorical_accuracy: 0.9305\n",
            "comm_round: 12 | local_acc: 89.001% | local_loss: 1.49609375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3377 - categorical_accuracy: 0.8974\n",
            "comm_round: 12 | local_acc: 52.704% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2278 - categorical_accuracy: 0.9265\n",
            "comm_round: 12 | local_acc: 75.318% | local_loss: 1.623046875\n",
            "69120\n",
            "comm_round: 12 | global_acc: 93.553% | global_loss: 1.458984375\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3797 - categorical_accuracy: 0.8922\n",
            "comm_round: 13 | local_acc: 10.575% | local_loss: 2.251953125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2284 - categorical_accuracy: 0.9359\n",
            "comm_round: 13 | local_acc: 80.023% | local_loss: 1.5830078125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1971 - categorical_accuracy: 0.9376\n",
            "comm_round: 13 | local_acc: 77.579% | local_loss: 1.62109375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2711 - categorical_accuracy: 0.9298\n",
            "comm_round: 13 | local_acc: 80.504% | local_loss: 1.5771484375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2417 - categorical_accuracy: 0.9294\n",
            "comm_round: 13 | local_acc: 64.742% | local_loss: 1.7255859375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2168 - categorical_accuracy: 0.9380\n",
            "comm_round: 13 | local_acc: 75.144% | local_loss: 1.638671875\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.3632 - categorical_accuracy: 0.8935\n",
            "comm_round: 13 | local_acc: 30.052% | local_loss: 2.060546875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2030 - categorical_accuracy: 0.9360\n",
            "comm_round: 13 | local_acc: 68.890% | local_loss: 1.6806640625\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2216 - categorical_accuracy: 0.9346\n",
            "comm_round: 13 | local_acc: 89.213% | local_loss: 1.501953125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2236 - categorical_accuracy: 0.9347\n",
            "comm_round: 13 | local_acc: 83.112% | local_loss: 1.556640625\n",
            "69120\n",
            "comm_round: 13 | global_acc: 94.842% | global_loss: 1.4443359375\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1973 - categorical_accuracy: 0.9420\n",
            "comm_round: 14 | local_acc: 80.937% | local_loss: 1.5771484375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5140 - categorical_accuracy: 0.8489\n",
            "comm_round: 14 | local_acc: 18.533% | local_loss: 2.15625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1999 - categorical_accuracy: 0.9443\n",
            "comm_round: 14 | local_acc: 80.870% | local_loss: 1.5810546875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.5253 - categorical_accuracy: 0.8442\n",
            "comm_round: 14 | local_acc: 21.055% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1789 - categorical_accuracy: 0.9477\n",
            "comm_round: 14 | local_acc: 89.117% | local_loss: 1.494140625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1894 - categorical_accuracy: 0.9434\n",
            "comm_round: 14 | local_acc: 81.803% | local_loss: 1.5693359375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2118 - categorical_accuracy: 0.9391\n",
            "comm_round: 14 | local_acc: 80.129% | local_loss: 1.591796875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2037 - categorical_accuracy: 0.9378\n",
            "comm_round: 14 | local_acc: 84.267% | local_loss: 1.54296875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2275 - categorical_accuracy: 0.9296\n",
            "comm_round: 14 | local_acc: 62.567% | local_loss: 1.7470703125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2190 - categorical_accuracy: 0.9398\n",
            "comm_round: 14 | local_acc: 70.997% | local_loss: 1.6708984375\n",
            "69120\n",
            "comm_round: 14 | global_acc: 93.851% | global_loss: 1.4521484375\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2835 - categorical_accuracy: 0.9301\n",
            "comm_round: 15 | local_acc: 53.387% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.3188 - categorical_accuracy: 0.9097\n",
            "comm_round: 15 | local_acc: 17.552% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.3406 - categorical_accuracy: 0.8943\n",
            "comm_round: 15 | local_acc: 9.623% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1907 - categorical_accuracy: 0.9447\n",
            "comm_round: 15 | local_acc: 80.139% | local_loss: 1.5830078125\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1893 - categorical_accuracy: 0.9393\n",
            "comm_round: 15 | local_acc: 77.271% | local_loss: 1.6025390625\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1948 - categorical_accuracy: 0.9418\n",
            "comm_round: 15 | local_acc: 87.538% | local_loss: 1.5166015625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1943 - categorical_accuracy: 0.9434\n",
            "comm_round: 15 | local_acc: 87.471% | local_loss: 1.5146484375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3735 - categorical_accuracy: 0.8871\n",
            "comm_round: 15 | local_acc: 17.360% | local_loss: 2.19921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.2050 - categorical_accuracy: 0.9444\n",
            "comm_round: 15 | local_acc: 82.390% | local_loss: 1.572265625\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2633 - categorical_accuracy: 0.9243\n",
            "comm_round: 15 | local_acc: 87.240% | local_loss: 1.5224609375\n",
            "69120\n",
            "comm_round: 15 | global_acc: 91.388% | global_loss: 1.478515625\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3406 - categorical_accuracy: 0.9019\n",
            "comm_round: 16 | local_acc: 73.162% | local_loss: 1.646484375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2121 - categorical_accuracy: 0.9392\n",
            "comm_round: 16 | local_acc: 88.279% | local_loss: 1.515625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1637 - categorical_accuracy: 0.9538\n",
            "comm_round: 16 | local_acc: 87.192% | local_loss: 1.5107421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2470 - categorical_accuracy: 0.9282\n",
            "comm_round: 16 | local_acc: 54.273% | local_loss: 1.8212890625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1385 - categorical_accuracy: 0.9611\n",
            "comm_round: 16 | local_acc: 91.157% | local_loss: 1.4736328125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1430 - categorical_accuracy: 0.9551\n",
            "comm_round: 16 | local_acc: 80.658% | local_loss: 1.57421875\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1617 - categorical_accuracy: 0.9522\n",
            "comm_round: 16 | local_acc: 87.452% | local_loss: 1.5078125\n",
            "69120\n",
            "216/216 [==============================] - 32s 147ms/step - loss: 0.1534 - categorical_accuracy: 0.9524\n",
            "comm_round: 16 | local_acc: 63.761% | local_loss: 1.734375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.3231 - categorical_accuracy: 0.8977\n",
            "comm_round: 16 | local_acc: 9.623% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1776 - categorical_accuracy: 0.9479\n",
            "comm_round: 16 | local_acc: 64.579% | local_loss: 1.7236328125\n",
            "69120\n",
            "comm_round: 16 | global_acc: 95.554% | global_loss: 1.4267578125\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1640 - categorical_accuracy: 0.9488\n",
            "comm_round: 17 | local_acc: 82.044% | local_loss: 1.5732421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1952 - categorical_accuracy: 0.9421\n",
            "comm_round: 17 | local_acc: 80.639% | local_loss: 1.580078125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1695 - categorical_accuracy: 0.9476\n",
            "comm_round: 17 | local_acc: 89.020% | local_loss: 1.4970703125\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3016 - categorical_accuracy: 0.9084\n",
            "comm_round: 17 | local_acc: 53.551% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 32s 147ms/step - loss: 0.1743 - categorical_accuracy: 0.9482\n",
            "comm_round: 17 | local_acc: 73.711% | local_loss: 1.6396484375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2266 - categorical_accuracy: 0.9357\n",
            "comm_round: 17 | local_acc: 9.623% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1562 - categorical_accuracy: 0.9527\n",
            "comm_round: 17 | local_acc: 85.498% | local_loss: 1.5263671875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1657 - categorical_accuracy: 0.9489\n",
            "comm_round: 17 | local_acc: 90.339% | local_loss: 1.5\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1604 - categorical_accuracy: 0.9499\n",
            "comm_round: 17 | local_acc: 83.083% | local_loss: 1.5458984375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1799 - categorical_accuracy: 0.9447\n",
            "comm_round: 17 | local_acc: 81.274% | local_loss: 1.572265625\n",
            "69120\n",
            "comm_round: 17 | global_acc: 94.659% | global_loss: 1.4404296875\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.3063 - categorical_accuracy: 0.9085\n",
            "comm_round: 18 | local_acc: 28.541% | local_loss: nan\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1689 - categorical_accuracy: 0.9537\n",
            "comm_round: 18 | local_acc: 57.246% | local_loss: 1.810546875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1965 - categorical_accuracy: 0.9437\n",
            "comm_round: 18 | local_acc: 80.687% | local_loss: 1.5771484375\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1521 - categorical_accuracy: 0.9538\n",
            "comm_round: 18 | local_acc: 85.989% | local_loss: 1.521484375\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1536 - categorical_accuracy: 0.9532\n",
            "comm_round: 18 | local_acc: 77.627% | local_loss: 1.607421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1960 - categorical_accuracy: 0.9380\n",
            "comm_round: 18 | local_acc: 75.751% | local_loss: 1.626953125\n",
            "69120\n",
            "216/216 [==============================] - 32s 147ms/step - loss: 0.1519 - categorical_accuracy: 0.9503\n",
            "comm_round: 18 | local_acc: 67.283% | local_loss: 1.7041015625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2518 - categorical_accuracy: 0.9343\n",
            "comm_round: 18 | local_acc: 29.388% | local_loss: 2.07421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 146ms/step - loss: 0.1613 - categorical_accuracy: 0.9486\n",
            "comm_round: 18 | local_acc: 72.739% | local_loss: 1.6533203125\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.3865 - categorical_accuracy: 0.8959\n",
            "comm_round: 18 | local_acc: 47.402% | local_loss: 1.904296875\n",
            "69120\n",
            "comm_round: 18 | global_acc: 93.851% | global_loss: 1.4501953125\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1366 - categorical_accuracy: 0.9564\n",
            "comm_round: 19 | local_acc: 89.088% | local_loss: 1.4921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1472 - categorical_accuracy: 0.9527\n",
            "comm_round: 19 | local_acc: 86.191% | local_loss: 1.5224609375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1775 - categorical_accuracy: 0.9540\n",
            "comm_round: 19 | local_acc: 68.408% | local_loss: 1.6884765625\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.2002 - categorical_accuracy: 0.9395\n",
            "comm_round: 19 | local_acc: 75.260% | local_loss: 1.6240234375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1801 - categorical_accuracy: 0.9431\n",
            "comm_round: 19 | local_acc: 57.323% | local_loss: 1.794921875\n",
            "69120\n",
            "216/216 [==============================] - 31s 145ms/step - loss: 0.1438 - categorical_accuracy: 0.9541\n",
            "comm_round: 19 | local_acc: 82.891% | local_loss: 1.5498046875\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.1776 - categorical_accuracy: 0.9460\n",
            "comm_round: 19 | local_acc: 63.029% | local_loss: 1.7421875\n",
            "69120\n",
            "216/216 [==============================] - 31s 144ms/step - loss: 0.1784 - categorical_accuracy: 0.9467\n",
            "comm_round: 19 | local_acc: 78.243% | local_loss: 1.59765625\n",
            "69120\n",
            "216/216 [==============================] - 31s 146ms/step - loss: 0.1633 - categorical_accuracy: 0.9480\n",
            "comm_round: 19 | local_acc: 61.952% | local_loss: 1.755859375\n",
            "69120\n",
            "216/216 [==============================] - 32s 146ms/step - loss: 0.2914 - categorical_accuracy: 0.9097\n",
            "comm_round: 19 | local_acc: 14.001% | local_loss: 2.232421875\n",
            "69120\n",
            "comm_round: 19 | global_acc: 96.045% | global_loss: 1.423828125\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "comms_round = 20\n",
        "for comm_round in range(comms_round):\n",
        "            \n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    \n",
        "    \n",
        "    global_weights = global_model.get_weights()\n",
        "    \n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    #random.shuffle(client_names)\n",
        "    \n",
        "    #loop through each client and create new local model\n",
        "    count = 0\n",
        "    for client in client_names:\n",
        "        \n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "        \n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
        "        test_local_model(X_test, y_test, local_model, comm_round)\n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "        \n",
        "        #clear session to free memory after each communication round\n",
        "        \n",
        "        # K.clear_session()\n",
        "        # gc.collect()\n",
        "        #del local_model\n",
        "    \n",
        "        \n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "    \n",
        "    #update global model \n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_global_model(X_test, Y_test, global_model, comm_round)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joi-pdrde-_R",
        "outputId": "58c2d6cc-7248-470f-c3f7-9a57267a3e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADI       1.00      0.98      0.99      1000\n",
            "        BACK       0.99      1.00      1.00      1069\n",
            "         DEB       0.93      0.94      0.94      1207\n",
            "         LYM       0.96      1.00      0.98      1233\n",
            "         MUC       0.93      0.99      0.96      1026\n",
            "         MUS       0.97      0.94      0.95      1364\n",
            "        NORM       1.00      0.92      0.96       877\n",
            "         STR       0.93      0.90      0.91      1164\n",
            "         TUM       0.95      0.98      0.96      1452\n",
            "\n",
            "    accuracy                           0.96     10392\n",
            "   macro avg       0.96      0.96      0.96     10392\n",
            "weighted avg       0.96      0.96      0.96     10392\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Plot the confusion matrix. Set Normalize = True/False\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predict_x=global_model.predict(X_test) \n",
        "y_pred=np.argmax(predict_x,axis=1)\n",
        "\n",
        "y_testreport=np.argmax(y_test,axis=1)\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Print Classification Report\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_testreport, y_pred, target_names=[\"ADI\", \"BACK\",\"DEB\", \"LYM\",\"MUC\", \"MUS\",\"NORM\", \"STR\",\"TUM\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "qDx1rI5FfBmv",
        "outputId": "46b8a758-e17e-4650-c310-ec196db9cf95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "Confusion matrix, without normalization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import itertools\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(y_testreport, y_pred)\n",
        "plot_confusion_matrix(cm, [\"ADI\", \"BACK\",\"DEB\", \"LYM\",\"MUC\", \"MUS\",\"NORM\", \"STR\",\"TUM\"], title='Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9u14l-3gfCgS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FedaratedLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}